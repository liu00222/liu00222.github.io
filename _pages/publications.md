---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---



**Yupei Liu**, Yuqi Jia, Jinyuan Jia, Dawn Song, and Neil Zhenqiang Gong. "[DataSentinel: A Game-Theoretic Detection of Prompt Injection Attacks](https://arxiv.org/pdf/2504.11358)". In *IEEE Symposium on Security and Privacy (IEEE S&P)*, 2025.  [<span style="color:red">[Distinguished Paper Award]</span>](https://sp2025.ieee-security.org/awards.html)  [<span style="color:red">[code]</span>](https://github.com/liu00222/Open-Prompt-Injection)


Lingyu Du, **Yupei Liu**, Jinyuan Jia, and Guohao Lan. "[SecureGaze: Defending Gaze Estimation Against Backdoor Attacks](https://arxiv.org/pdf/2502.20306?)". In *Conference on Embedded Networked Sensor Systems (SenSys)*, 2025. [<span style="color:red">[code]</span>](https://github.com/LingyuDu/SecureGaze)


**Yupei Liu**, Yuqi Jia, Jinyuan Jia, and Neil Zhenqiang Gong. "[Evaluating LLM-based Personal Information Extraction and Countermeasures](https://arxiv.org/abs/2408.07291)". In *USENIX Security Symposium*, 2025.  [<span style="color:red">[code]</span>](https://zenodo.org/records/14737200)


**Yupei Liu**, Yanting Wang, and Jinyuan Jia. "[TrojanDec: Data-free Detection of Trojan Testing Inputs in Self-supervised Learning](https://arxiv.org/pdf/2501.04108)". In *AAAI Conference on Artificial Intelligence (AAAI)*, 2025.


**Yupei Liu**, Yuqi Jia, Runpeng Geng, Jinyuan Jia, and Neil Zhenqiang Gong. "[Formalizing and Benchmarking Prompt Injection Attacks and Defenses](https://arxiv.org/abs/2310.12815)". In *USENIX Security Symposium*, 2024.  [<span style="color:red">[video]</span>](https://www.youtube.com/watch?v=ymVcsf2s_OY) 
 [<span style="color:red">[code]</span>](https://github.com/liu00222/Open-Prompt-Injection)


Jinyuan Jia\*, **Yupei Liu\***, Yuepeng Hu, and Neil Zhenqiang Gong. "[PORE: Provably Robust Recommender Systems against Data Poisoning Attacks](https://arxiv.org/abs/2303.14601)". In *USENIX Security Symposium*, 2023.  [<span style="color:red">[code]</span>](https://github.com/liu00222/PORE-Provably-Robust-Recommender-Systems-against-Data-Poisoning-Attacks)


**Yupei Liu**, Jinyuan Jia, Hongbin Liu, and Neil Zhenqiang Gong. "[StolenEncoder: Stealing Pre-trained Encoders in Self-supervised Learning](https://arxiv.org/pdf/2201.05889.pdf)". In *ACM Conference on Computer and Communications Security (CCS)*, 2022.  [<span style="color:red">[code]</span>](https://github.com/liu00222/StolenEncoder)


Jinyuan Jia, **Yupei Liu**, Xiaoyu Cao, and Neil Zhenqiang Gong. "[Certified Robustness of Nearest Neighbors against Data Poisoning and Backdoor Attacks](https://www.aaai.org/AAAI22Papers/AAAI-3833.JiaJ.pdf)". In *AAAI Conference on Artificial Intelligence (AAAI)*, 2022.  [<span style="color:red">[video]</span>](https://aaai-2022.virtualchair.net/poster_aaai3833)


R. Spencer Hallyburton, **Yupei Liu**, Yulong Cao, Z. Morley Mao, and Miroslav Pajic. "[Security Analysis of Camera-LiDAR Fusion Against Black-Box Attacks on Autonomous Vehicles](https://www.usenix.org/conference/usenixsecurity22/presentation/hallyburton)". In *USENIX Security Symposium*, 2022.  [<span style="color:red">[code]</span>](https://gitlab.oit.duke.edu/cpsl/secureperception/frustumattack) 


Jinyuan Jia\*, **Yupei Liu\***, and Neil Zhenqiang Gong. "[BadEncoder: Backdoor Attacks to Pre-trained Encoders in Self-Supervised Learning](https://arxiv.org/pdf/2108.00352.pdf)". In *IEEE Symposium on Security and Privacy (IEEE S&P)*, 2022.  [<span style="color:red">[code]</span>](https://github.com/jjy1994/BadEncoder)

\*Equal contribution
